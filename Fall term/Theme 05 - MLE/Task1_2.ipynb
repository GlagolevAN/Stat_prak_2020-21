{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random as rnd\n",
    "import math as m\n",
    "import pandas as pd\n",
    "import scipy.stats as stat\n",
    "import scipy.optimize as opt\n",
    "import seaborn as sb\n",
    "from scipy.integrate import quad\n",
    "from scipy.integrate import dblquad\n",
    "from scipy.special import comb\n",
    "\n",
    "#plt.style.use('ggplot')\n",
    "\n",
    "my_norm = lambda exp, disp: stat.norm(loc = exp, scale = m.sqrt(disp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x19db6012040>]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "expon = lambda theta: stat.expon(loc = theta)\n",
    "x = np.linspace(0, 10, 1000)\n",
    "plt.plot(x, stat.cauchy(loc = 3).pdf(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = 15; samplesize = 500;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def likelihood(distr, sample):\n",
    "    L = 0\n",
    "    for i in range(len(sample)):\n",
    "        L += np.log(distr(sample[i]))\n",
    "    return L;\n",
    "\n",
    "def likelihood_c(theta):\n",
    "    return -likelihood(stat.cauchy(loc = theta).pdf, sample = mini_sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.636254697646592 36.73918846031948\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 14.900999\n",
      "         Iterations: 4\n",
      "         Function evaluations: 30\n",
      "         Gradient evaluations: 15\n",
      "[10.12085869]\n"
     ]
    }
   ],
   "source": [
    "mini_sample = stat.cauchy(loc = theta).rvs(5)\n",
    "print(likelihood_c(2), likelihood_c(30))\n",
    "res = opt.minimize(likelihood_c, 42, method = \"BFGS\")\n",
    "print(res.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n = 5\n",
      "MLE: \n",
      "10.00357034192482 1.598644986795077\n",
      "MED: \n",
      "10.012673958524395 0.9129620624794053\n",
      "n = 10\n",
      "MLE: \n",
      "10.013337409278197 0.3307068984591449\n",
      "MED: \n",
      "10.068375201203008 0.3876646454285874\n",
      "n = 20\n",
      "MLE: \n",
      "10.029709539854618 0.12061881770009525\n",
      "MED: \n",
      "10.030310780836391 0.1478567019754451\n",
      "n = 50\n",
      "MLE: \n",
      "10.00933799737576 0.04071604425313355\n",
      "MED: \n",
      "10.01736800477241 0.05182570427804542\n",
      "n = 100\n",
      "MLE: \n",
      "10.002491723905164 0.018201970138321498\n",
      "MED: \n",
      "10.001402715423003 0.023182827869717572\n"
     ]
    }
   ],
   "source": [
    "samplesize = 500\n",
    "\n",
    "for n in [5, 10, 20, 50, 100]:\n",
    "    MLEsample = []; MEDsample = []\n",
    "    for i in range(samplesize):\n",
    "        mini_sample = stat.cauchy(loc = theta).rvs(n)\n",
    "\n",
    "        MLEsample.append(opt.minimize(likelihood_c, 5, method = \"BFGS\").x)\n",
    "        MEDsample.append(np.median(mini_sample))\n",
    "        #print(res)\n",
    "       \n",
    "    print('n =', n)\n",
    "    print(\"MLE: \")\n",
    "    print(np.array(MLEsample).mean(), np.array(MLEsample).var())\n",
    "\n",
    "    print(\"MED: \")\n",
    "    print(np.array(MEDsample).mean(), np.array(MEDsample).var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling_method(distr, sample):\n",
    "    D = distr(sample[0])\n",
    "    for i in range(1, len(sample) - 1):\n",
    "        D *= (distr(sample[i]) - distr(sample[i - 1]))\n",
    "    D *= (1 - distr(sample[len(sample) - 1]))\n",
    "    return m.exp(D) * 10 ** len(sample);\n",
    "\n",
    "def likelihood_n(theta):\n",
    "    return -likelihood(stat.norm(loc = theta).pdf, sample = mini_sample)\n",
    "\n",
    "def sampling_method_n(theta):\n",
    "    return -sampling_method(stat.norm(loc = theta).cdf, sample = mini_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Likelihood 36.48344501393161 4586.146817365735\n",
      "Sampling method estimate -1.0\n",
      "-0.34771039092326783\n"
     ]
    }
   ],
   "source": [
    "theta = 0\n",
    "mini_sample = sorted(stat.norm(loc = theta).rvs(10))\n",
    "#print(mini_sample)\n",
    "#print(stat.norm(loc = theta).cdf(mini_sample))\n",
    "print(\"Likelihood\", likelihood_n(2), likelihood_n(30))\n",
    "print(\"Sampling method estimate\", sampling_method_n(5))\n",
    "res = opt.minimize_scalar(sampling_method_n)\n",
    "print(res.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n = 5\n",
      "MLE estimation: 10.018657846126787\n",
      "MSE estimation: 9.843866646225282\n",
      "MLE is better 55 times\n",
      "MSE is better 45 times\n",
      "MLE is better\n",
      "n = 10\n",
      "MLE estimation: 9.957413983867651\n",
      "MSE estimation: 8.957413991361314\n",
      "MLE is better 95 times\n",
      "MSE is better 5 times\n",
      "MLE is better\n",
      "n = 20\n",
      "MLE estimation: 10.026569013720167\n",
      "MSE estimation: 9.026569021007278\n",
      "MLE is better 99 times\n",
      "MSE is better 1 times\n",
      "MLE is better\n",
      "n = 50\n",
      "MLE estimation: 9.998963763101555\n",
      "MSE estimation: 8.998963767682968\n",
      "MLE is better 100 times\n",
      "MSE is better 0 times\n",
      "MLE is better\n",
      "n = 100\n",
      "MLE estimation: 10.007887880736991\n",
      "MSE estimation: 9.007887886224806\n",
      "MLE is better 100 times\n",
      "MSE is better 0 times\n",
      "MLE is better\n"
     ]
    }
   ],
   "source": [
    "samplesize = 100\n",
    "theta = 10\n",
    "\n",
    "#x_axis = np.linspace(0, 30, 10000)\n",
    "\n",
    "for n in [5, 10, 20, 50, 100]:\n",
    "    MLEsample = []; MSEsample = []\n",
    "    for i in range(samplesize):\n",
    "        mini_sample = sorted(stat.norm(loc = theta).rvs(n))\n",
    "        #print(mini_sample)\n",
    "        mean = np.array(mini_sample).mean()\n",
    "        MLEsample.append(opt.minimize(likelihood_n, mean - 1, method = \"BFGS\").x[0])\n",
    "        #print(sampling_method_n(theta))\n",
    "        MSEsample.append(opt.minimize(sampling_method_n, mean - 1, method = \"BFGS\").x[0]);\n",
    "        \n",
    "        #plt.plot(x_axis, [sampling_method_n(elem) for elem in x_axis]);\n",
    "        #plt.show()\n",
    "       # print(MSEsample)\n",
    "        \n",
    "    print('n =', n)\n",
    "    print(\"MLE estimation:\", np.array(MLEsample).mean())\n",
    "    print(\"MSE estimation:\", np.array(MSEsample).mean())\n",
    "    \n",
    "    MLE_better = 0; MSE_better = 0;\n",
    "    \n",
    "    for i in range(samplesize):\n",
    "        if (abs(theta - MLEsample[i]) < abs(theta - MSEsample[i])):\n",
    "            MLE_better += 1\n",
    "        else: \n",
    "            MSE_better += 1\n",
    "    \n",
    "    \n",
    "    print(\"MLE is better\", MLE_better, \"times\")\n",
    "    print(\"MSE is better\", MSE_better, \"times\")\n",
    "    if (MLE_better > MSE_better):\n",
    "        print(\"MLE is better\")\n",
    "    else:\n",
    "        print(\"MSE is better\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n = 5\n",
      "MLE estimation: 15.005724953428542\n",
      "MSE estimation: 14.832700152587893\n",
      "MLE is better 559 times\n",
      "MSE is better 441 times\n",
      "MLE is better\n",
      "n = 10\n",
      "MLE estimation: 14.996284606831248\n",
      "MSE estimation: 14.868303283691409\n",
      "MLE is better 588 times\n",
      "MSE is better 412 times\n",
      "MLE is better\n",
      "n = 20\n",
      "MLE estimation: 15.000539977393833\n",
      "MSE estimation: 14.920392309570314\n",
      "MLE is better 575 times\n",
      "MSE is better 425 times\n",
      "MLE is better\n",
      "n = 50\n",
      "MLE estimation: 14.992424775228981\n",
      "MSE estimation: 14.952053387451175\n",
      "MLE is better 572 times\n",
      "MSE is better 428 times\n",
      "MLE is better\n",
      "n = 100\n",
      "MLE estimation: 14.999855481823303\n",
      "MSE estimation: 14.976971429443362\n",
      "MLE is better 553 times\n",
      "MSE is better 447 times\n",
      "MLE is better\n"
     ]
    }
   ],
   "source": [
    "def likelihood(distr, sample):\n",
    "    L = 0\n",
    "    for i in range(len(sample)):\n",
    "        L += np.log(distr(sample[i]))\n",
    "    return L;\n",
    "\n",
    "def likelihood_c(theta):\n",
    "    return -likelihood(stat.cauchy(loc = theta).pdf, sample = mini_sample)\n",
    "\n",
    "''''''\n",
    "\n",
    "\n",
    "\n",
    "samplesize = 1000\n",
    "\n",
    "for n in [5, 10, 20, 50, 100]:\n",
    "    MLEsample = []; MSEsample = []\n",
    "    for i in range(samplesize):\n",
    "        mini_sample = sorted(stat.norm(loc = theta).rvs(n))\n",
    "        #print(mini_sample)\n",
    "        MLEsample.append(opt.minimize(likelihood_n, 13, method = \"BFGS\").x[0])\n",
    "        MSEsample.append(opt.fmin(lambda theta: sampling_method_n(theta), 13, disp = 0)[0]);\n",
    "       # print(MSEsample)\n",
    "        \n",
    "    print('n =', n)\n",
    "    print(\"MLE estimation:\", np.array(MLEsample).mean())\n",
    "    print(\"MSE estimation:\", np.array(MSEsample).mean())\n",
    "    \n",
    "    MLE_better = 0; MSE_better = 0;\n",
    "    \n",
    "    for i in range(samplesize):\n",
    "        if (abs(theta - MLEsample[i]) < abs(theta - MSEsample[i])):\n",
    "            MLE_better += 1\n",
    "        else: \n",
    "            MSE_better += 1\n",
    "    \n",
    "    \n",
    "    print(\"MLE is better\", MLE_better, \"times\")\n",
    "    print(\"MSE is better\", MSE_better, \"times\")\n",
    "    if (MLE_better > MSE_better):\n",
    "        print(\"MLE is better\")\n",
    "    else:\n",
    "        print(\"MSE is better\")\n",
    "        \n",
    "    #sb.distplot()\n",
    "    \n",
    "    '''\n",
    "    print('n =', n)\n",
    "    print(\"MLE: \")\n",
    "    print(np.array(MLEsample).mean(), np.array(MLEsample).var())\n",
    "\n",
    "    print(\"MED: \")\n",
    "    print(np.array(MEDsample).mean(), np.array(MEDsample).var())\n",
    "    '''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in [2, 5, 10, 20, 50, 100, 500]:\n",
    "    data1 = []\n",
    "    data2 = []\n",
    "    for i in range(samplesize):\n",
    "        sample = expon(theta).rvs(n);\n",
    "        data1.append(sample.min() - 1 / n)\n",
    "        data2.append(sample.mean() - 1)\n",
    "    sb.distplot(data1, hist = False, label = '$X_{(1)} - 1 / n$');\n",
    "    sb.distplot(data2, hist = False, label = '$\\\\overline{X} - 1$');\n",
    "    plt.axvline(theta)\n",
    "    plt.title(\"$\\\\overline{X} - 1$ for n = \" + str(n));\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for n in [2, 5, 10, 20, 50, 100, 500]:\n",
    "    data1 = []\n",
    "    data2 = []\n",
    "    theta = 10\n",
    "    for i in range(samplesize):\n",
    "        sample = expon(theta).rvs(n);\n",
    "        sample_mod = np.array([i * (i - 2) for i in sample])\n",
    "        #print(sample_mod.mean())\n",
    "        data1.append(m.sqrt(n) * (sample.mean() - 1 - theta))\n",
    "        \n",
    "        #try:\n",
    "        data2.append(m.sqrt(n) * (m.sqrt(sample_mod.mean()) - theta))\n",
    "        #    break\n",
    "        #except ValueError:\n",
    "        #    print(\"Mean is less than two\")\n",
    "        \n",
    "    sb.distplot(data1, label = '$\\\\sqrt{n} \\\\cdot (\\\\overline{X} - 1 - \\\\theta)$');\n",
    "    sb.distplot(data2, label = '$\\\\sqrt{n} \\\\cdot (\\\\sqrt{\\\\overline{X^2 - 2X}} - \\\\theta)$');\n",
    "    #plt.axvline(theta)\n",
    "    plt.title(\"n = \" + str(n));\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
